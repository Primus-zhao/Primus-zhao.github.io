---
title: "The Consciousness Prior: 构造意识－通往自由之路"
date: 2017-09-27
categories:
  - Post
last_modified_at: 2017-09-27T21:00:25-00:00
---


首先非常抱歉我标题党了一把，盗用了哈耶克的著作名来换热度。在一般情况下，将一篇文章与未来发展方向结合起来往往会有夸大其辞的嫌疑。但是这篇文章比较特殊，一篇只有区区４页的论文却阐述了通往意识之路的途径。因为这篇文章的意义，我也会摒弃往日轻快随意的文风，非常严肃的来讨论这篇文章阐述的构建意识推理方面的问题。

# Is everything OK?
掩盖在当前人工智能领域快速发展背后的一个严重问题就是如何将从CV，NLP得到的信息与人脑已有的知识进行有效组织，从而根据这些信息进行推理。在这其中还有一个信息表示的巨大跨度。CV的信息更多的是转化为对于图像处理后的类别、位置等物理意义，而NLP则往往是输出词语或者声音的coding。这些coding及物理意义都是人为赋予的，这也就导致了为了能够根据得到的这些信息进行有效推理，我们必须再构建知识图谱来适应这些编码从而进行search或者简单推理。这种方法符合人类对问题表征的理解，但是却不符合人类内部对于信息处理和推理的机制，所以导致其基本没有迁移的办法，只能根据特定领域进行特定的知识库搭建，而推理的过程也往往具有机械化地设计和生搬硬套的意味。目前看来还没有好的统一的基于各方面信息进行推理的机制。
而这篇文章真正的价值就在于纲要上给出了对意识进行抽象和建模的可能性。下面我们来详细分析：

# 什么是意识

意识在认知心理学中早已给出定义，但是这个定义更多基于生理研究方面，对于人工智能理论研究的意义不大。这篇文章对于意识的定义是一种高度抽象的机制，这种机制在我们采用稀疏的注意力机制来获得状态表征的一个子集之后，可以基于这个子集得出关于现实或行为的有用推断。这种定义方式从认知心理学的角度讲可能过于狭隘，但是已经足够我们围绕它进行意识模型的构建。

## 意识先验理论

意识先验理论中的大部分模型具有强化学习的色彩，从我们先前对于意识的定义中可以看出，它和强化学习的构建环境具有非常相似的架构。都是从环境获得的数据进行行为或者状态的有效判断，只是强化学习更多地强调与环境多轮互动的特性。
首先我们假设\\(S_t\\)是在时间t的观测状态，而\\(h_t\\)则定义为从\\(S_t\\)获得的一个高级别表征，那么我们有很多办法来对他们的相互关系进行一个时序上的建模。

$$h_t=F(s_t, h_{t-1})$$

这个建模方式有多种选择，一个常见的选择方式就是RNN。在这种情况下，我们将其成为表征RNN或编码器。这个模型的核心目的是得到一个好的\\(h_t\\)，这个变量可以将抽象层面上可解释的因素都分离开，这样我们可以通过对其进行变换实现单个因素信息的提取。而这个建模用的RNN，我们可以在理想地把它想象为涵盖了脑中在t时刻具有的所有信息，这样这个\\(h_t\\)就会成为一个很高维的向量（毕竟承载了大量的信息，而如果我们想要建立的向量模拟人类的特点的话，其表征信息往往还具有稀疏性），同时由于建立的模型具有时序性，所以当前的\\(h_t\\)也会承载大量过去的信息。
对应这种高维变量我们还要定义一个意识状态\\(c_t\\)，它是一个从\\(h_t\\)上运用注意力机制推出的低维向量。

$$c_t=C(h_t, c_{t-1}, z_t)$$

其中的\\(z_t\\)是随机噪声源。这里的\\(c_t\\)表示思想所具有的内容，也就是无意识状态下获得的所有当前信息中的一个子集，却由于注意力机制而被从\\(h_t\\)投射到了我们的表层意识当中。这里的函数C被称为意识RNN。由于我们在计算中加入了随机变量，所以每次注意力机制得到的元素会有所区别。这条性质在对未来的计划、预测进行探索时非常有用（这种方式和强化学习中的\\(\epsilon \\)更新方法非常相似。从另外一个角度，由于函数C实现了降维，所以我们也可以将它理解成一个提取信息，将有用信息从杂乱无章的内容中抽晰出来的一个办法。

## 模型训练目标

前面提到过，意识状态\\(c_t\\)担负着对未来进行预测或者行为规划的作用，如果想要了解其是否具有了这个作用，就必须提出一种评价机制，一个可行的方案是构建一个验证网络(Verfier network)，对当前所有信息和过去的意识状态之间的一致性进行打分：

$$V(h_t, c_{t-k})$$

从普遍意义上讲，其实就是想构建一个用来训练表征网络和意识网络的可量化的评价机制。除了评价之外，可能也包括一些其他的目的，比如尽量保证提出的信息能够重构输入值等等。
关于该目标函数的构建元素选取上有两种方案：１）采用注意力机制来将高维表征转化为低维意识；２）直接对基于意识得到的预测结果或者行为进行评价。后者的操作方案很容易实现，和我们现行的机器学习和深度学习的目标函数构建方式非常相似。但是具有更大意义的前者实现起来则非常困难，道理如下：假设我们目前已知状态子集B，而我们的目的是得到关于将来的状态预测的子集A。为了保证得到最好的模型效果，我们的目标函数会设定为最大化logP(A|B)或一些近似。但是此处我们需要注意到，我们的建模并不只是为了预测的更加准确，而是希望训练的函数能够贴近表征RNN的真实形式，而对于这一部分的目标函数几乎无法评估。此外，在使用注意力机制时，也无法找到注意力究竟应该集中在哪些元素上（应该注意A还是B?其实都不是。事实上，注意力应该集中在从A到B的映射机制上)。如果在实际应用中我们采用了之前提到的logP(A|B)作为目标函数，那么在给定B之后我们总会选择B作为预测值，而这种无用的映射绝对不是我们想要的结果。所以目标函数一定还要涵盖一些其他的评价机制，这目前还是一个开放性的问题，一个解决方案是采用强化能够学习的回报来实现这一效果，不过由于构建表征RNN的过程及影响估计都很漫长，这并非一个最佳解决方案。从原理上讲，还需要一些其他的熵和多样性来保证注意力机制的随机性，这对于保证在训练过程中注意到的元素的覆盖范围是有很大帮助的。

## 变量命名

这里指出了引入构建表征向量键值对的作用。由于键值对的构建，意识状态就必须间接映射到表征状态上了，与直接从特征向量比多出了一层抽象，但是是否会对构建意识函数有帮助目前我还持保留意见。而如果大量表征状态都引入到验证网络中的话，简单的网络训练算法可能无法提供足够大的梯度（这是论文中的观点，个人观点在进行变量命名后确实使验证网络的训练变的简单，但是这是建立在通过命名实现了一层抽象的基础上，从这个角度来讲，抽象的工作其实并未减少）。

## 与语言的相关性

事实上，引入感知状态的过程跟采用语言对信息进行抽象的过程非常相似（比如用语言来描述一幅图片）。语言可以用来描述意识状态，但是需要注意的是，通常意识状态的信息量是大于语言的，而语言抽象构建的过程中更多的是考虑到信息传递的相关性和时效性，所以可以采用另一个RNN来对语言和意识状态之间的信息进行建模

$$u_t=U(c_t, u_{t-1})$$

其中的u是t时刻的语言表达。语言对于表征网络的构建很有帮助。由于通常一个句子中只有少量的元素和概念，不像我们的意识状态可能包含大量信息，而且单个词语或短语往往代表某个独立含义，所以如果将语言的元素作为评价基准加入到表征网络的训练当中就可以得到好的表征的粒度效果，也就是得到具有较大变化的特征表示（类似于冲击函数）。
类似地，如果我们将类似的概念引入深度学习和其相对应的高级别感知和知识表示中，就可以找到一个搭接其他们的桥梁。知识表示和语言非常相似，简短的句子当中包含少量概念和信息。这样就可以在训练深度神经网络的过程中对其加入规则化特性，得到非常漂亮的信息表征方案。

# 如何对意识先验进行实验？

由于该理论的根基非常浅，本着由易到难的宗旨。首先应该从一些简单示例入手。其次，虽然语言可以提升意识先验模型的效果，但是为了真正实现模拟人类意识，最好首先不要引入语言，毕竟我们在掌握语言之前就已经能够意识到很多物理特性。第三，最好先将其置于非监督强化学习当中，以进行效果评估。第四，最好采用一些有意义的抽象对其进行测试，比如判断桌上的一摞东西是否会掉到低声等等，用这些实验来判断意识先验是否掌握了物理定律。如果某个时间的结果是有大量变量及多模型协同决定的，那么由于未来时间的熵值很高，对其进行预测的难度非常大。但是如果影响的因素非常少，而定律也比较简单，那么意识先验就有可能派上用场。最后，如果要进行实验结果比较的话，直接将意识先验与强化学习进行比较吧，毕竟同宗同源。
