---
title: "Post: Edge detection(系列I)"
date: 2017-09-12
categories:
  - Post
last_modified_at: 2017-09-12T22:21:25-05:00
---

边缘检测作为图像处理的基本任务之一，在不同的阶段都得到了广泛研究。哎！像个老学究似的说话太烦了，接下来我们用轻松愉快的方式来开始这篇博客。其实边缘检测也算是个老生长谈的问题了，从早先的各种梯度算子，到伟大的Canny（车道线检测的同学肯定会点赞），再到后来的Ncut及一些变种。还是取得了不错的效果的。不过悲剧的是，几乎所有效果好一些的算子都有各种各样的超参需要调节。这对于经验和运气都是很大的考验。
然后时间来到了2012年，那是深度学习初露峥嵘之年，几位大神手持CNN和LSTM两把宝剑把图像领域砍的四分五裂，而边缘检测，作为图像处理佔板上的肥肉，自然少不了被来上两刀。首先拿边缘检测祭刀的便是\\(N^4-Fields\\)算法

## N4-Fields  

首先吐槽一下，这名字简直来的莫名其妙，该算法全称为Neural Network and Nearest Neighbor，中译版叫神经网络和最近邻。作者为了偷懒，取了4个首字母就搞定了算法命名。按这种起名方式，我将来要是开发了个算法Fast Unary Convolutional Kernel的话情何以勘啊。当然，吐槽归吐槽，算法还是要分析的，下面我们来简明扼要的描述一下：
其实按照现在观点看来，这文章干货并不是非常多。如果有赶时间的同学看完下面这句话基本就可以跳过该篇文章的分析了：首先对图片采用卷积后求均值的方式得到转化值（实质上就是提取图片特征向量），然后对特征向量采用PCA降维，然后将得到的向量采用k近邻的方式求得分类。So easy哈？确实如此
下面有闲情逸致的同学可以和我一起来看下该方法的具体细节，这其中也会包含无尽的公式作为bonus，二话不说，先来一个残暴的公式，对每个像素的转化计算可以表示为：

$$F(I)[x,y]=\frac{1}{N^2}\sum_{i,j:|i-x|<=N/2,|j-y|<=N/2}F(I(i,j|M))[x-i,y-j]$$

(排版不是很好看，但是不要在意这些细节！！！）
公式看起来很恶心对吧，看到较长公式会产生呕吐感的同学可以尝试通过以下这句话缓解一下：首先把图片按某种模式或是算法进行转化得到一堆M大小的batch图片, 然后想求哪个点的输出值把所有转化出的图片在该位置的值求和再来个平均就搞定。当然，我们需要注意到该网络并非全卷积网络，为了方便最近后用kNN算法进行距离计算，最后用了两层全连来降维，降维后的输出维度为16。
 值得一提的是，为了相应科学界潮男们的号召，转化过程采用了卷积。得到了新图之后下一个任务就是用最近邻来得到最优分类啦。闲话少说，直接上公式：

 $$F(\Rho)=NNB(CNN(\Rho;\theta)|\{(CNN(\Rho;\theta);A(\Rho_i))|i=1..T\})$$ 

隐藏在复杂公式下的是及其简单的道理，建立一个样例池，计算出的特征和样例池中的那个特征距离近它就属于哪类。那其实该算法的核心就在于样例池的建立方案上。这部分的解决方案也非常直接，从训练集中随机选图后做降维。步骤如下：

1. 首先从训练集中随机取一些样例，通过他们来得到PCA映射矩阵
2. 使用得到的矩阵对训练集进行PCA降维后作为卷积神经的目标值，采用\\(\{\Rho,PCA(A(\Rho))\}\\)作为训练对来训练卷积神经网络
3. 从训练集中随机抽取T个样例构成键值对\\(\{(CNN(\Rho_i; \Theta)|A(\Rho_i))|i=1..T\})来构成k近邻算法的字典。T值的选取方式论文中没有提及，但是按照正常经验来看在能够保证速度的情况下尽量调大可以保证训练精度，但是过大的话对泛化性能又会产生负面影响，所以需要根据validation值进行调参。

## 测试过程

文章里面用了几个小trick来提升精度以及提高kNN的速度（毕竟具有成千上万个键值的kNN计算可不是闹着玩的）。
1. 由于测试图片的大小未必和训练集相同，所以需要某些机制匹配，最naive的想法当然就是sliding window，在享受这naive带给我们乐趣的同时我们也必须忍受此君渣一般的速度。文章提出了用sequence of shifted test images的方法（实话实说，这方法我也没听说过，以后还得补补课）
2. 将测试图像转化为不同分辨率，并对这些分辨率分别计算边缘，然后再求个平均。（这个技巧在原文中只说了3行，也许在当时只是作为一个小trick拿来提升精度，但是从后面卷积神经网络的发展来看，却展现了非常重要的从不同感受野的卷积数据来提取特征的重要思想，后期的几乎所有涉及到像素级别的深度学习处理：如定位的faster RCNN, SSD, yolo系列， 分割的FCN, Deeplab, 边缘检测的RCF，甚至于最近的Fully connected densenet都有这种思想的踪影，这也说明了科学研究确实有无心插柳柳成茵的现象）
3. 使用了投票机制（委员会机制）来提升精度，这个也是常用技巧了，几乎所有的ensemble模型都依赖于它，所以也不用多说。

后面还有一些实验内容的比较，因为该方法目前已经不是state of art，所以实验比较意义已经不大，改天把实验中的图传上来给大家个感性认识此篇就完活儿。

